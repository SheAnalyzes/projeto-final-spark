{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65216a0d-5de9-44a5-9d68-6a9103f8ab7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Estrutura dos arquivos:\n",
    "\n",
    "src\n",
    "├── libs\n",
    "│   ├── dataframe.py\n",
    "│   ├── conexaoDB.py\n",
    "│   ├── criarTabelas.py\n",
    "│   ├── fraudes.py\n",
    "├── files\n",
    "│   ├── csv_clientes\n",
    "│   ├── csv_transacoes\n",
    "├── main.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5748a84-76c9-4e2a-bc59-0104528cc607",
   "metadata": {},
   "source": [
    "inicializando pyspark e criando uma sessão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bef9a6ca-71ca-418b-9b7f-7d9b2eccfbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Teste\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387eb558-4ab5-478a-ab7c-4f4f3cb05219",
   "metadata": {},
   "source": [
    "CRIANDO DATAFRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0d96799c-cbdd-4598-b2d8-70112a6ef798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "class Data():\n",
    "    '''A classe Dataframe tem o objetivo de proporcionar métodos capazes de ler arquivos CSVs, gerar dataframes e modificá-los.'''\n",
    "     \n",
    "    def __init__(self, csv_path,tipo):\n",
    "        #self.spark = SparkHelper.getInstance().spark\n",
    "        self.csv_path = csv_path\n",
    "        self.tipo = tipo\n",
    "        #self.spark = SparkSession.builder.master(\"local[*]\").appName(\"b\").getOrCreate()\n",
    "        \n",
    "    def criar(self):\n",
    "        '''O método criar procura ler uma pasta que contém arquivo CSV gerando um dataframe.'''\n",
    "        self.path_completo = self.csv_path + self.tipo + '-0**.csv'\n",
    "        print(self.path_completo)\n",
    "        \n",
    "        #Lendo o arquivo CSV bruto\n",
    "        try:\n",
    "            self.df_bruto = spark.read.csv(self.path_completo, sep=\";\", header=False, inferSchema=True)\n",
    "        except AnalysisException:\n",
    "            print('O path nao existe. Por favor, insira um path valido.\\nPode ser que o \"tipo\" passado nao seja \"clients\", \"transaction_in\" ou \"transaction_out\".')\n",
    "            return 0\n",
    "            \n",
    "        # Filtrando o header. Note que está considerando que se tiverem vários headers, apenas 1 será selecionado\n",
    "        self.header = self.df_bruto.filter(col(\"_c0\") == \"id\").limit(1)\n",
    "\n",
    "        # Excluindo o/os header do Dataframe bruto\n",
    "        df_filtrado = self.df_bruto.where((col(\"_c0\") != \"id\"))\n",
    "\n",
    "        # Convertendo a primeira linha do header em uma lista de strings\n",
    "        header_columns = self.header.first()\n",
    "\n",
    "        # Gerando um dataframe com o header certo\n",
    "        self.df = df_filtrado.toDF(*header_columns)\n",
    "        print(self.df.count())\n",
    "\n",
    "        return self.df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97615a8a-a54f-408f-90e4-05df911e7971",
   "metadata": {},
   "source": [
    "TESTANDO NA CLASSE - CLIENTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "69a69c4e-ac10-4f26-8812-ae74b6353d77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/app/files/client-0**.csv\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "Path does not exist: file:/home/jovyan/app/files/client-0**.csv",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m csv_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/jovyan/app/files/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m csv_path2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/jovyan/app/files\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m df_clientes1 \u001b[38;5;241m=\u001b[39m \u001b[43mData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclient\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriar\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#df_clientes1.show()\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[39], line 19\u001b[0m, in \u001b[0;36mData.criar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_completo)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#Lendo o arquivo CSV bruto\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf_bruto \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_completo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m;\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minferSchema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''except AnalysisException:\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m    print('O tipo passado nao eh \"clients\", \"transaction_in\" ou \"transaction_out\".')\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m    return 0\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m    except AnalysisException:\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m    print('O path nao existe. Por favor, insira um path valido')\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Filtrando o header. Note que está considerando que se tiverem vários headers, apenas 1 será selecionado\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/readwriter.py:535\u001b[0m, in \u001b[0;36mDataFrameReader.csv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(path) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spark\u001b[38;5;241m.\u001b[39m_sc\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoSeq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, RDD):\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(iterator):\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Path does not exist: file:/home/jovyan/app/files/client-0**.csv"
     ]
    }
   ],
   "source": [
    "csv_path = '/home/jovyan/app/files/'\n",
    "csv_path2 = '/home/jovyan/app/files'\n",
    "\n",
    "df_clientes1 = Data(csv_path,'client').criar()\n",
    "#df_clientes1.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b82b9a4-62a3-4687-812d-e796735b6bcc",
   "metadata": {},
   "source": [
    "testando sem ser na classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d49a19c8-a55a-4a3d-84d8-72e3ecf64421",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/app/files/clients-0**.csv\n",
      "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string]\n",
      "+---+--------------------+--------------------+--------------------+----------------+\n",
      "|_c0|                 _c1|                 _c2|                 _c3|             _c4|\n",
      "+---+--------------------+--------------------+--------------------+----------------+\n",
      "| 55|   Edmilson da silva|edmilson-da-silva...|2019-08-29 21:54:...|+55(22)2922-2626|\n",
      "| 78|Maxson Barros do ...|maxson-barros-do-...|2019-09-09 23:03:...|+55(22)2126-2529|\n",
      "| 61| Bruno cesar e silva|bruno-cesar-e-sil...|2019-08-29 22:05:...|+55(23)2528-2729|\n",
      "|106|Dernival passos d...|dernival-passos-d...|2019-09-26 23:40:...|+55(29)2927-2322|\n",
      "|107| José rubian de goes|jose-rubian-de-go...|2019-09-28 10:09:...|+55(22)2023-2620|\n",
      "|108|Angelica Dos Sant...|angelica-dos-sant...|2019-09-28 11:48:...|+55(20)2521-3030|\n",
      "|109|          Alanderson|alanderson_109@gm...|2019-09-28 21:15:...|+55(22)2323-2426|\n",
      "|142|      Silvio gabriel|silvio-gabriel_14...|2019-10-04 09:47:...|+55(22)3026-2123|\n",
      "|144|JOSÉ CARLOS DA SI...|jose-carlos-da-si...|2019-10-06 11:24:...|+55(21)2921-2127|\n",
      "|145|Dante Hugo Ayres ...|dante-hugo-ayres-...|2019-10-06 13:36:...|+55(20)2421-2129|\n",
      "|146|FELIPE EMANUEL DA...|felipe-emanuel-da...|2019-10-06 15:24:...|+55(25)2020-2820|\n",
      "| 88|Anderson albuquerque|anderson-albuquer...|2019-09-14 17:52:...|+55(29)2527-2125|\n",
      "|159|               Arena| arena_159@gmail.com|2019-10-31 15:56:...|+55(28)2127-2623|\n",
      "|150|                Jean|  jean_150@gmail.com|2019-10-13 17:50:...|+55(30)2028-2130|\n",
      "|248|              Daniel|daniel_248@gmail.com|2019-12-12 20:54:...|+55(22)2328-2725|\n",
      "|156|     Ronaldo Rabello|ronaldo-rabello_1...|2019-10-25 14:26:...|+55(25)3026-2124|\n",
      "|157|    Alexandre Santos|alexandre-santos_...|2019-10-26 13:48:...|+55(27)2825-2325|\n",
      "|160|Genival rufino ne...|genival-rufino-ne...|2019-10-31 17:13:...|+55(25)2225-2922|\n",
      "|152|             Bandeja|bandeja_152@gmail...|2019-10-16 10:03:...|+55(24)2727-2527|\n",
      "|153|DANTE HUGO BRANDA...|dante-hugo-branda...|2019-10-16 23:09:...|+55(30)2430-2227|\n",
      "+---+--------------------+--------------------+--------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tipo = 'clients'\n",
    "csv_path = '/home/jovyan/app/files/'\n",
    "teste = csv_path + tipo + '-0**.csv'\n",
    "print(teste)\n",
    "try:\n",
    "    df_bruto = spark.read.csv('/home/jovyan/app/files/clients-0**.csv', sep=\";\", header=False, inferSchema=True) \n",
    "except:\n",
    "    print('O tipo passado nao eh \"clients\", \"transaction_in\" ou \"transaction_out\".')\n",
    "print(df_bruto)\n",
    "df_bruto.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8455751a-3bda-477b-97c1-7b046a484faa",
   "metadata": {},
   "source": [
    "TESTANDO NA CLASSE - TRANSACOES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8b4b49ce-3f4b-4dca-83f6-fac01070f382",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+-----+-------------------+\n",
      "|  id|cliente_id|valor|               data|\n",
      "+----+----------+-----+-------------------+\n",
      "|8615|       586|  0.2|2022-01-19 20:12:26|\n",
      "|8613|       586|  0.2|2022-01-19 20:11:25|\n",
      "|8611|       586|  0.2|2022-01-19 20:10:05|\n",
      "|8606|       910|300.0|2022-01-19 19:59:36|\n",
      "|8604|        76|100.0|2022-01-18 12:48:14|\n",
      "|8603|        76|100.0|2022-01-18 12:48:04|\n",
      "|8602|        76|100.0|2022-01-18 12:47:47|\n",
      "|8601|        76|100.0|2022-01-18 12:47:43|\n",
      "|8600|        76|100.0|2022-01-18 12:47:39|\n",
      "|8599|        76|100.0|2022-01-18 12:43:05|\n",
      "|8598|        76|100.0|2022-01-18 12:42:56|\n",
      "|8597|        76|100.0|2022-01-18 12:40:28|\n",
      "|8596|        76|100.0|2022-01-18 12:38:19|\n",
      "|8595|        76|100.0|2022-01-18 12:37:59|\n",
      "|8594|        76|100.0|2022-01-18 12:37:29|\n",
      "|8593|        76|100.0|2022-01-18 12:37:19|\n",
      "|8592|       907| 10.0|2022-01-18 12:30:26|\n",
      "|8591|       907| 10.0|2022-01-18 12:30:14|\n",
      "|8590|       907| 10.0|2022-01-18 12:30:10|\n",
      "|8589|       907| 10.0|2022-01-18 12:30:04|\n",
      "+----+----------+-----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "expression 'transacoesin.id' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\nAggregate [cliente_id#2365], [id#2364, cliente_id#2365, valor#2366, data#2367]\n+- SubqueryAlias transacoesin\n   +- View (`TransacoesIn`, [id#2364,cliente_id#2365,valor#2366,data#2367])\n      +- Union false, false\n         :- Relation [id#2364,cliente_id#2365,valor#2366,data#2367] csv\n         +- Relation [_c0#2389,_c1#2390,_c2#2391,_c3#2392] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m df_transacoes_in\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Executa uma consulta SQL para filtrar as fraudes\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m fraudes \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSELECT * FROM TransacoesIn GROUP BY cliente_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m                     \u001b[38;5;66;03m#data_cadastro LIKE '2021-03-28 %:00:%'\")\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Exibe o resultado\u001b[39;00m\n\u001b[1;32m     15\u001b[0m fraudes\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py:1034\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery, **kwargs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m     sqlQuery \u001b[38;5;241m=\u001b[39m formatter\u001b[38;5;241m.\u001b[39mformat(sqlQuery, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1034\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: expression 'transacoesin.id' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;\nAggregate [cliente_id#2365], [id#2364, cliente_id#2365, valor#2366, data#2367]\n+- SubqueryAlias transacoesin\n   +- View (`TransacoesIn`, [id#2364,cliente_id#2365,valor#2366,data#2367])\n      +- Union false, false\n         :- Relation [id#2364,cliente_id#2365,valor#2366,data#2367] csv\n         +- Relation [_c0#2389,_c1#2390,_c2#2391,_c3#2392] csv\n"
     ]
    }
   ],
   "source": [
    "header_transacoes_in_path = \"/home/jovyan/app/files/csv_transacoes/transacoes_in/header-transaction-in-001.csv\"\n",
    "transacoes_in_path = \"/home/jovyan/app/files/csv_transacoes/transacoes_in/transaction-in-00*.csv\"\n",
    "\n",
    "df_transacoes_in = Dataframe(transacoes_in_path).criar(header_transacoes_in_path)\n",
    "\n",
    "df_transacoes_in.show()\n",
    "\n",
    "df_transacoes_in.createOrReplaceTempView(\"TransacoesIn\")\n",
    "df_transacoes_in\n",
    "# Executa uma consulta SQL para filtrar as fraudes\n",
    "\n",
    "fraudes = spark.sql(\"SELECT * FROM TransacoesIn GROUP BY cliente_id\")\n",
    "                    #data_cadastro LIKE '2021-03-28 %:00:%'\")\n",
    "\n",
    "# Exibe o resultado\n",
    "fraudes.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3c50adbe-80e2-437b-a5ba-d6506a9bc526",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+-------------------+----------------+\n",
      "| id|                nome|               email|      data_cadastro|        telefone|\n",
      "+---+--------------------+--------------------+-------------------+----------------+\n",
      "|641|Priscila Felix do...|priscila-felix-do...|2021-03-28 18:46:57|+55(30)2227-2428|\n",
      "| 94|             idelmon|idelmon_94@gmail.com|2019-09-19 12:33:19|+55(29)3027-2026|\n",
      "|584|Liliane soares da...|liliane-soares-da...|2021-02-10 19:15:30|+55(21)2024-2520|\n",
      "|580|Fagner jose dos s...|fagner-jose-dos-s...|2021-02-07 01:47:04|+55(24)2624-2029|\n",
      "| 21|               Cildo|  cildo_21@gmail.com|2019-07-30 11:40:10|+55(21)2222-2422|\n",
      "|582|Nielton da Silva ...|nielton-da-silva-...|2021-02-09 00:11:22|+55(27)2028-2828|\n",
      "|586|Armando Teles da ...|armando-teles-da-...|2021-02-12 15:20:14|+55(27)2720-2230|\n",
      "|151|            Fabricio|fabricio_151@gmai...|2019-10-14 21:16:27|+55(20)2121-2326|\n",
      "| 83|       Flavio junior|flavio-junior_83@...|2019-09-11 15:24:00|+55(22)2028-2122|\n",
      "|587|              Wagner|wagner_587@gmail.com|2021-02-14 13:56:25|+55(28)2620-2421|\n",
      "|585|         Jeine maria|jeine-maria_585@g...|2021-02-11 23:49:04|+55(27)2528-2523|\n",
      "|534|                Thay|  thay_534@gmail.com|2020-12-19 02:10:58|+55(29)2327-2626|\n",
      "|639|Sindini vieira do...|sindini-vieira-do...|2021-03-21 16:07:04|+55(28)2126-2123|\n",
      "|528|           Aparecido|aparecido_528@gma...|2020-12-12 20:02:38|+55(26)2721-2828|\n",
      "|636|         Edy Navarro|edy-navarro_636@g...|2021-03-04 11:29:03|+55(30)3024-2821|\n",
      "|626|        Moab Tenorio|moab-tenorio_626@...|2021-02-21 14:49:26|+55(29)2921-2730|\n",
      "|627|     Jose Franciusci|jose-franciusci_6...|2021-02-21 14:53:39|+55(29)2222-2227|\n",
      "|637|Crislane luiz da ...|crislane-luiz-da-...|2021-03-07 03:11:09|+55(30)2821-2024|\n",
      "|635|             Emerson|emerson_635@gmail...|2021-03-03 23:03:31|+55(20)2224-2829|\n",
      "|638|               Italo| italo_638@gmail.com|2021-03-15 23:19:48|+55(25)2323-2424|\n",
      "+---+--------------------+--------------------+-------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97ef6c2-363a-4518-b69b-ab08d008629a",
   "metadata": {},
   "source": [
    "TESTANDO SEM ESTAR NA CLASSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58abdb83-ae71-4524-8783-df91e82c31e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404\n",
      "+---+--------------------+--------------------+--------------------+----------------+\n",
      "| id|                nome|               email|       data_cadastro|        telefone|\n",
      "+---+--------------------+--------------------+--------------------+----------------+\n",
      "| 55|   Edmilson da silva|edmilson-da-silva...|2019-08-29 21:54:...|+55(22)2922-2626|\n",
      "| 78|Maxson Barros do ...|maxson-barros-do-...|2019-09-09 23:03:...|+55(22)2126-2529|\n",
      "| 61| Bruno cesar e silva|bruno-cesar-e-sil...|2019-08-29 22:05:...|+55(23)2528-2729|\n",
      "|106|Dernival passos d...|dernival-passos-d...|2019-09-26 23:40:...|+55(29)2927-2322|\n",
      "|107| José rubian de goes|jose-rubian-de-go...|2019-09-28 10:09:...|+55(22)2023-2620|\n",
      "|108|Angelica Dos Sant...|angelica-dos-sant...|2019-09-28 11:48:...|+55(20)2521-3030|\n",
      "|109|          Alanderson|alanderson_109@gm...|2019-09-28 21:15:...|+55(22)2323-2426|\n",
      "|142|      Silvio gabriel|silvio-gabriel_14...|2019-10-04 09:47:...|+55(22)3026-2123|\n",
      "|144|JOSÉ CARLOS DA SI...|jose-carlos-da-si...|2019-10-06 11:24:...|+55(21)2921-2127|\n",
      "|145|Dante Hugo Ayres ...|dante-hugo-ayres-...|2019-10-06 13:36:...|+55(20)2421-2129|\n",
      "|146|FELIPE EMANUEL DA...|felipe-emanuel-da...|2019-10-06 15:24:...|+55(25)2020-2820|\n",
      "| 88|Anderson albuquerque|anderson-albuquer...|2019-09-14 17:52:...|+55(29)2527-2125|\n",
      "|159|               Arena| arena_159@gmail.com|2019-10-31 15:56:...|+55(28)2127-2623|\n",
      "|150|                Jean|  jean_150@gmail.com|2019-10-13 17:50:...|+55(30)2028-2130|\n",
      "|248|              Daniel|daniel_248@gmail.com|2019-12-12 20:54:...|+55(22)2328-2725|\n",
      "|156|     Ronaldo Rabello|ronaldo-rabello_1...|2019-10-25 14:26:...|+55(25)3026-2124|\n",
      "|157|    Alexandre Santos|alexandre-santos_...|2019-10-26 13:48:...|+55(27)2825-2325|\n",
      "|160|Genival rufino ne...|genival-rufino-ne...|2019-10-31 17:13:...|+55(25)2225-2922|\n",
      "|152|             Bandeja|bandeja_152@gmail...|2019-10-16 10:03:...|+55(24)2727-2527|\n",
      "|153|DANTE HUGO BRANDA...|dante-hugo-branda...|2019-10-16 23:09:...|+55(30)2430-2227|\n",
      "+---+--------------------+--------------------+--------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Lendo o arquivo CSV bruto\n",
    "df_bruto = spark.read.csv(\"/home/jovyan/app/files/csv_clientes/\", sep=\";\", header=False, mode=\"DROPMALFORMED\")\n",
    "\n",
    "# Filtrando o header. Note que está considerado que se tiverem vários headers, apenas 1 será selecionado\n",
    "header = df_bruto.filter(col(\"_c0\") == \"id\").limit(1)\n",
    "\n",
    "# Excluindo o/os header do Dataframe bruto\n",
    "df_filtrado = df_bruto.where((col(\"_c0\") != \"id\"))\n",
    "\n",
    "# Convertendo a primeira linha do header em uma lista de strings\n",
    "header_columns = header.first()\n",
    "\n",
    "# Gerando um dataframe com o header certo\n",
    "df = df_filtrado.toDF(*header_columns)\n",
    "\n",
    "# Exibindo o resultado\n",
    "print(df.count())\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a56d107-2bbf-4f26-8837-d5fcaf8a0eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79327ea8-98a7-4705-9698-39271d5b17b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
